{"cells":[{"cell_type":"markdown","metadata":{"id":"SjyXyt4eckLC"},"source":["# Using several classifiers and tuning parameters - Parameters grid\n","[From official `scikit-learn` documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html)\n","\n","Adapted by Claudio Sartori\n","\n","Example of usage of the ***model selection*** features of `scikit-learn` and comparison of several classification methods.\n","1. import a sample dataset \n","1. split the dataset into two parts: train and test\n","    - the *train* part will be used for training and validation (i.e. for *development*)\n","    - the *test* part will be used for test (i.e. for *evaluation*)\n","    - the fraction of test data will be _ts_ (a value of your choice between 0.2 and 0.5)\n","1. the function `GridSearchCV` iterates a cross validation experiment to train and test a model with different combinations of paramater values\n","    - for each parameter we set a list of values to test, the function will generate all the combinations\n","    - we choose a *score function* which will be used for the optimization\n","        - e.g. `accuracy_score`, `precision_score`, `cohen_kappa_score`, `f1_score`, see this [page](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for reference\n","    - the output is a dictionary containing \n","        - the set of parameters which maximize the score \n","        - the test scores\n","1. prepare the parameters for the grid\n","    - it is a list of dictionaries\n","1. set the parameters by cross validation and the *score functions* to choose from\n","1. Loop on scores and, for each score, loop on the model labels (see details below)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwEJNWgEckLJ","executionInfo":{"status":"ok","timestamp":1672410748510,"user_tz":-60,"elapsed":1330,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}},"outputId":"8d3ec0e9-25a1-4825-cae4-f2b7e1bb8cb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n","@author: scikit-learn.org and Claudio Sartori\n","\n"]}],"source":["\"\"\"\n","http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n","@author: scikit-learn.org and Claudio Sartori\n","\"\"\"\n","import warnings\n","warnings.filterwarnings('ignore') # uncomment this line to suppress warnings\n","\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.svm import SVC\n","from sklearn.linear_model import Perceptron\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n","\n","print(__doc__) # print information included in the triple quotes at the beginning\n","\n","# Loading a standard dataset\n","#dataset = datasets.load_digits()\n","#dataset = datasets.fetch_olivetti_faces()\n","#dataset = datasets.fetch_covtype()\n","dataset = datasets.load_iris()\n","#dataset = datasets.load_wine()\n","#dataset = datasets.load_breast_cancer()"]},{"cell_type":"markdown","metadata":{"id":"P32Gxwp_ckLL"},"source":["### Prepare the environment\n","The `dataset` module contains, among others, a few sample datasets.\n","\n","See this [page](http://scikit-learn.org/stable/datasets/index.html) for reference\n","\n","Prepare the data and the target in X and y. Set `ts`. Set the random state to 42"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"c8jwwwOgckLM","executionInfo":{"status":"ok","timestamp":1672410855246,"user_tz":-60,"elapsed":230,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}}},"outputs":[],"source":["X = dataset.data\n","y = dataset.target\n","ts = 0.3\n","random_state = 42"]},{"cell_type":"markdown","metadata":{"id":"ogwiJrAHckLM"},"source":["Split the dataset into the train and test parts"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwkXw8E1ckLN","executionInfo":{"status":"ok","timestamp":1672410856473,"user_tz":-60,"elapsed":3,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}},"outputId":"ec20f6c5-ff65-487b-d1ce-2d28fde9e6da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on  105  examples\n"]}],"source":["from sklearn.model_selection import train_test_split\n","Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,test_size = ts, random_state = random_state)\n","print(\"Training on \", Xtrain.shape[0], \" examples\")"]},{"cell_type":"markdown","metadata":{"id":"Pu5zMmfbckLO"},"source":["The code below is intended to ease the remainder of the exercise"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"w0EDC4G2ckLO","executionInfo":{"status":"ok","timestamp":1672410871180,"user_tz":-60,"elapsed":239,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}}},"outputs":[],"source":["model_lbls = [\n","              'dt', \n","              'nb', \n","              'lp', \n","              'svc', \n","             'knn',\n","             'adb',\n","             'rf',\n","            ]\n","\n","# Set the parameters by cross-validation\n","tuned_param_dt = [{'max_depth': [*range(1,20)]}]\n","tuned_param_nb = [{'var_smoothing': [10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-07, 1e-8, 1e-9, 1e-10]}]\n","tuned_param_lp = [{'early_stopping': [True]}]\n","tuned_param_svc = [{'kernel': ['rbf'], \n","                    'gamma': [1e-3, 1e-4],\n","                    'C': [1, 10, 100, 1000],\n","                    },\n","                    {'kernel': ['linear'],\n","                     'C': [1, 10, 100, 1000],                     \n","                    },\n","                   ]\n","tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n","tuned_param_adb = [{'n_estimators':[20,30,40,50],\n","                   'learning_rate':[0.5,0.75,1,1.25,1.5]}]\n","tuned_param_rf = [{'max_depth': [*range(5,15)],\n","                   'n_estimators':[*range(10,100,10)]}]\n","\n","models = {\n","    'dt': {'name': 'Decision Tree       ',\n","           'estimator': DecisionTreeClassifier(), \n","           'param': tuned_param_dt,\n","          },\n","    'nb': {'name': 'Gaussian Naive Bayes',\n","           'estimator': GaussianNB(),\n","           'param': tuned_param_nb\n","          },\n","    'lp': {'name': 'Linear Perceptron   ',\n","           'estimator': Perceptron(),\n","           'param': tuned_param_lp,\n","          },\n","    'svc':{'name': 'Support Vector      ',\n","           'estimator': SVC(), \n","           'param': tuned_param_svc\n","          },\n","    'knn':{'name': 'K Nearest Neighbor ',\n","           'estimator': KNeighborsClassifier(),\n","           'param': tuned_param_knn\n","       },\n","       'adb':{'name': 'AdaBoost           ',\n","           'estimator': AdaBoostClassifier(),\n","           'param': tuned_param_adb\n","          },\n","    'rf': {'name': 'Random forest       ',\n","           'estimator': RandomForestClassifier(),\n","           'param': tuned_param_rf\n","          }\n","\n","}\n","\n","scores = ['precision_micro', 'recall_micro']"]},{"cell_type":"markdown","metadata":{"id":"4cFyKKUpckLP"},"source":["### The function below groups all the outputs\n","Write a function which has as parameter the fitted model and uses the components of the fitted model to inspect the results of the search with the parameters grid.\n","\n","The components are:<br>\n","`model.best_params_`<br>\n","`model.cv_results_['mean_test_score']`<br>`\n","model.cv_results_['std_test_score']`<br>\n","`model.cv_results_['params']`\n","\n","The classification report is generated by the function imported above from sklearn.metrics, which takes as argument the true and the predicted test labels.\n","\n","The +/- in the results is obtained doubling the `std_test_score`\n","\n","The function will be used to print the results for each set of parameters"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"sL9pS1c7ckLQ","executionInfo":{"status":"ok","timestamp":1672411731334,"user_tz":-60,"elapsed":286,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}}},"outputs":[],"source":["def print_results(model):\n","    print(\"Best parameters set found on train set:\")\n","    print()\n","    # if best is linear there is no gamma parameter\n","    print(model.best_params_)\n","    print()\n","    print(\"Grid scores on train set:\")\n","    print()\n","    means = model.cv_results_['mean_test_score']\n","    stds = model.cv_results_['std_test_score']\n","    params = model.cv_results_['params']\n","    for mean, std, params_tuple in zip(means, stds, params):\n","        print(\"%0.3f (+/-%0.03f) for %r\"\n","              % (mean, std * 2, params_tuple))\n","    print()\n","    print(\"Detailed classification report for the best parameter set:\")\n","    print()\n","    print(\"The model is trained on the full train set.\")\n","    print(\"The scores are computed on the full test set.\")\n","    print()\n","    y_true, y_pred = ytest, model.predict(Xtest)\n","    print(classification_report(y_true, y_pred))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"0Yr1wv-wckLS"},"source":["### Loop on scores and, for each score, loop on the model labels\n","- iterate varying the score function\n","    1. iterate varying the classification model among Decision Tree, Naive Bayes, Linear Perceptron, Support Vector, AdaBoost, Random Forest and KNN\n","        - activate the *grid search*\n","            1. the resulting model will be the best one according to the current score function\n","        - print the best parameter set and the results for each set of parameters using the above defined function\n","        - print the classification report\n","        - store the `.best score_` in a dictionary for a final report\n","    1. print the final report for the current *score funtion*"]},{"cell_type":"code","execution_count":20,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"jQ5gI4EBckLS","executionInfo":{"status":"ok","timestamp":1672412232597,"user_tz":-60,"elapsed":61799,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}},"outputId":"cfbbe22f-5ece-4442-c428-17feed949253"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameters set found on train set:\n","\n","{'max_depth': 9}\n","\n","Grid scores on train set:\n","\n","0.629 (+/-0.038) for {'max_depth': 1}\n","0.914 (+/-0.071) for {'max_depth': 2}\n","0.933 (+/-0.076) for {'max_depth': 3}\n","0.933 (+/-0.047) for {'max_depth': 4}\n","0.924 (+/-0.047) for {'max_depth': 5}\n","0.933 (+/-0.047) for {'max_depth': 6}\n","0.933 (+/-0.047) for {'max_depth': 7}\n","0.933 (+/-0.047) for {'max_depth': 8}\n","0.943 (+/-0.071) for {'max_depth': 9}\n","0.933 (+/-0.047) for {'max_depth': 10}\n","0.933 (+/-0.047) for {'max_depth': 11}\n","0.933 (+/-0.047) for {'max_depth': 12}\n","0.933 (+/-0.047) for {'max_depth': 13}\n","0.933 (+/-0.047) for {'max_depth': 14}\n","0.933 (+/-0.047) for {'max_depth': 15}\n","0.933 (+/-0.047) for {'max_depth': 16}\n","0.943 (+/-0.071) for {'max_depth': 17}\n","0.943 (+/-0.071) for {'max_depth': 18}\n","0.933 (+/-0.047) for {'max_depth': 19}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'var_smoothing': 0.001}\n","\n","Grid scores on train set:\n","\n","0.724 (+/-0.229) for {'var_smoothing': 10}\n","0.914 (+/-0.140) for {'var_smoothing': 1}\n","0.905 (+/-0.159) for {'var_smoothing': 0.1}\n","0.924 (+/-0.097) for {'var_smoothing': 0.01}\n","0.933 (+/-0.076) for {'var_smoothing': 0.001}\n","0.933 (+/-0.076) for {'var_smoothing': 0.0001}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-05}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-06}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-07}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-08}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-09}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      0.92      0.96        13\n","           2       0.93      1.00      0.96        13\n","\n","    accuracy                           0.98        45\n","   macro avg       0.98      0.97      0.97        45\n","weighted avg       0.98      0.98      0.98        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'early_stopping': True}\n","\n","Grid scores on train set:\n","\n","0.648 (+/-0.187) for {'early_stopping': True}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        19\n","           1       0.29      1.00      0.45        13\n","           2       0.00      0.00      0.00        13\n","\n","    accuracy                           0.29        45\n","   macro avg       0.10      0.33      0.15        45\n","weighted avg       0.08      0.29      0.13        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on train set:\n","\n","0.486 (+/-0.258) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.371 (+/-0.152) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.933 (+/-0.114) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.486 (+/-0.258) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.952 (+/-0.085) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.933 (+/-0.114) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.971 (+/-0.076) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.952 (+/-0.085) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.962 (+/-0.071) for {'C': 1, 'kernel': 'linear'}\n","0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n","0.952 (+/-0.085) for {'C': 100, 'kernel': 'linear'}\n","0.952 (+/-0.085) for {'C': 1000, 'kernel': 'linear'}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'n_neighbors': 1}\n","\n","Grid scores on train set:\n","\n","0.952 (+/-0.060) for {'n_neighbors': 1}\n","0.933 (+/-0.076) for {'n_neighbors': 2}\n","0.933 (+/-0.076) for {'n_neighbors': 3}\n","0.933 (+/-0.076) for {'n_neighbors': 4}\n","0.943 (+/-0.071) for {'n_neighbors': 5}\n","0.943 (+/-0.071) for {'n_neighbors': 6}\n","0.952 (+/-0.060) for {'n_neighbors': 7}\n","0.952 (+/-0.060) for {'n_neighbors': 8}\n","0.943 (+/-0.071) for {'n_neighbors': 9}\n","0.933 (+/-0.076) for {'n_neighbors': 10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'learning_rate': 1, 'n_estimators': 20}\n","\n","Grid scores on train set:\n","\n","0.914 (+/-0.071) for {'learning_rate': 0.5, 'n_estimators': 20}\n","0.905 (+/-0.060) for {'learning_rate': 0.5, 'n_estimators': 30}\n","0.905 (+/-0.060) for {'learning_rate': 0.5, 'n_estimators': 40}\n","0.905 (+/-0.060) for {'learning_rate': 0.5, 'n_estimators': 50}\n","0.924 (+/-0.047) for {'learning_rate': 0.75, 'n_estimators': 20}\n","0.924 (+/-0.047) for {'learning_rate': 0.75, 'n_estimators': 30}\n","0.914 (+/-0.071) for {'learning_rate': 0.75, 'n_estimators': 40}\n","0.924 (+/-0.047) for {'learning_rate': 0.75, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'learning_rate': 1, 'n_estimators': 20}\n","0.924 (+/-0.047) for {'learning_rate': 1, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'learning_rate': 1, 'n_estimators': 40}\n","0.924 (+/-0.047) for {'learning_rate': 1, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'learning_rate': 1.25, 'n_estimators': 20}\n","0.924 (+/-0.076) for {'learning_rate': 1.25, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'learning_rate': 1.25, 'n_estimators': 40}\n","0.924 (+/-0.076) for {'learning_rate': 1.25, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 20}\n","0.924 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 30}\n","0.924 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 40}\n","0.924 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 50}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'max_depth': 9, 'n_estimators': 50}\n","\n","Grid scores on train set:\n","\n","0.933 (+/-0.097) for {'max_depth': 5, 'n_estimators': 10}\n","0.933 (+/-0.047) for {'max_depth': 5, 'n_estimators': 20}\n","0.933 (+/-0.047) for {'max_depth': 5, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'max_depth': 5, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'max_depth': 5, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 90}\n","0.933 (+/-0.047) for {'max_depth': 6, 'n_estimators': 10}\n","0.933 (+/-0.047) for {'max_depth': 6, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 6, 'n_estimators': 30}\n","0.933 (+/-0.047) for {'max_depth': 6, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 70}\n","0.933 (+/-0.047) for {'max_depth': 6, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 90}\n","0.933 (+/-0.047) for {'max_depth': 7, 'n_estimators': 10}\n","0.933 (+/-0.047) for {'max_depth': 7, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 7, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 40}\n","0.933 (+/-0.047) for {'max_depth': 7, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 90}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 60}\n","0.933 (+/-0.097) for {'max_depth': 8, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 90}\n","0.933 (+/-0.047) for {'max_depth': 9, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 20}\n","0.933 (+/-0.047) for {'max_depth': 9, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'max_depth': 9, 'n_estimators': 40}\n","0.952 (+/-0.060) for {'max_depth': 9, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 60}\n","0.933 (+/-0.097) for {'max_depth': 9, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 90}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 10, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'max_depth': 10, 'n_estimators': 60}\n","0.933 (+/-0.047) for {'max_depth': 10, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 90}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 11, 'n_estimators': 30}\n","0.924 (+/-0.076) for {'max_depth': 11, 'n_estimators': 40}\n","0.952 (+/-0.085) for {'max_depth': 11, 'n_estimators': 50}\n","0.933 (+/-0.047) for {'max_depth': 11, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 90}\n","0.924 (+/-0.047) for {'max_depth': 12, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 90}\n","0.952 (+/-0.085) for {'max_depth': 13, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 90}\n","0.933 (+/-0.097) for {'max_depth': 14, 'n_estimators': 10}\n","0.933 (+/-0.047) for {'max_depth': 14, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 90}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'max_depth': 13}\n","\n","Grid scores on train set:\n","\n","0.629 (+/-0.038) for {'max_depth': 1}\n","0.914 (+/-0.071) for {'max_depth': 2}\n","0.933 (+/-0.076) for {'max_depth': 3}\n","0.933 (+/-0.047) for {'max_depth': 4}\n","0.924 (+/-0.047) for {'max_depth': 5}\n","0.933 (+/-0.047) for {'max_depth': 6}\n","0.933 (+/-0.047) for {'max_depth': 7}\n","0.933 (+/-0.047) for {'max_depth': 8}\n","0.933 (+/-0.047) for {'max_depth': 9}\n","0.933 (+/-0.047) for {'max_depth': 10}\n","0.933 (+/-0.047) for {'max_depth': 11}\n","0.933 (+/-0.047) for {'max_depth': 12}\n","0.943 (+/-0.071) for {'max_depth': 13}\n","0.933 (+/-0.047) for {'max_depth': 14}\n","0.933 (+/-0.047) for {'max_depth': 15}\n","0.933 (+/-0.047) for {'max_depth': 16}\n","0.933 (+/-0.047) for {'max_depth': 17}\n","0.933 (+/-0.047) for {'max_depth': 18}\n","0.933 (+/-0.047) for {'max_depth': 19}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'var_smoothing': 0.001}\n","\n","Grid scores on train set:\n","\n","0.724 (+/-0.229) for {'var_smoothing': 10}\n","0.914 (+/-0.140) for {'var_smoothing': 1}\n","0.905 (+/-0.159) for {'var_smoothing': 0.1}\n","0.924 (+/-0.097) for {'var_smoothing': 0.01}\n","0.933 (+/-0.076) for {'var_smoothing': 0.001}\n","0.933 (+/-0.076) for {'var_smoothing': 0.0001}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-05}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-06}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-07}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-08}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-09}\n","0.933 (+/-0.076) for {'var_smoothing': 1e-10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      0.92      0.96        13\n","           2       0.93      1.00      0.96        13\n","\n","    accuracy                           0.98        45\n","   macro avg       0.98      0.97      0.97        45\n","weighted avg       0.98      0.98      0.98        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'early_stopping': True}\n","\n","Grid scores on train set:\n","\n","0.648 (+/-0.187) for {'early_stopping': True}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        19\n","           1       0.29      1.00      0.45        13\n","           2       0.00      0.00      0.00        13\n","\n","    accuracy                           0.29        45\n","   macro avg       0.10      0.33      0.15        45\n","weighted avg       0.08      0.29      0.13        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on train set:\n","\n","0.486 (+/-0.258) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.371 (+/-0.152) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.933 (+/-0.114) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.486 (+/-0.258) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.952 (+/-0.085) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.933 (+/-0.114) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.971 (+/-0.076) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.952 (+/-0.085) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.962 (+/-0.071) for {'C': 1, 'kernel': 'linear'}\n","0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n","0.952 (+/-0.085) for {'C': 100, 'kernel': 'linear'}\n","0.952 (+/-0.085) for {'C': 1000, 'kernel': 'linear'}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'n_neighbors': 1}\n","\n","Grid scores on train set:\n","\n","0.952 (+/-0.060) for {'n_neighbors': 1}\n","0.933 (+/-0.076) for {'n_neighbors': 2}\n","0.933 (+/-0.076) for {'n_neighbors': 3}\n","0.933 (+/-0.076) for {'n_neighbors': 4}\n","0.943 (+/-0.071) for {'n_neighbors': 5}\n","0.943 (+/-0.071) for {'n_neighbors': 6}\n","0.952 (+/-0.060) for {'n_neighbors': 7}\n","0.952 (+/-0.060) for {'n_neighbors': 8}\n","0.943 (+/-0.071) for {'n_neighbors': 9}\n","0.933 (+/-0.076) for {'n_neighbors': 10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'learning_rate': 1, 'n_estimators': 20}\n","\n","Grid scores on train set:\n","\n","0.914 (+/-0.071) for {'learning_rate': 0.5, 'n_estimators': 20}\n","0.905 (+/-0.060) for {'learning_rate': 0.5, 'n_estimators': 30}\n","0.905 (+/-0.060) for {'learning_rate': 0.5, 'n_estimators': 40}\n","0.905 (+/-0.060) for {'learning_rate': 0.5, 'n_estimators': 50}\n","0.924 (+/-0.047) for {'learning_rate': 0.75, 'n_estimators': 20}\n","0.924 (+/-0.047) for {'learning_rate': 0.75, 'n_estimators': 30}\n","0.914 (+/-0.071) for {'learning_rate': 0.75, 'n_estimators': 40}\n","0.924 (+/-0.047) for {'learning_rate': 0.75, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'learning_rate': 1, 'n_estimators': 20}\n","0.924 (+/-0.047) for {'learning_rate': 1, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'learning_rate': 1, 'n_estimators': 40}\n","0.924 (+/-0.047) for {'learning_rate': 1, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'learning_rate': 1.25, 'n_estimators': 20}\n","0.924 (+/-0.076) for {'learning_rate': 1.25, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'learning_rate': 1.25, 'n_estimators': 40}\n","0.924 (+/-0.076) for {'learning_rate': 1.25, 'n_estimators': 50}\n","0.933 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 20}\n","0.924 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 30}\n","0.924 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 40}\n","0.924 (+/-0.097) for {'learning_rate': 1.5, 'n_estimators': 50}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Best parameters set found on train set:\n","\n","{'max_depth': 6, 'n_estimators': 30}\n","\n","Grid scores on train set:\n","\n","0.933 (+/-0.097) for {'max_depth': 5, 'n_estimators': 10}\n","0.933 (+/-0.047) for {'max_depth': 5, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 60}\n","0.933 (+/-0.097) for {'max_depth': 5, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 5, 'n_estimators': 90}\n","0.924 (+/-0.076) for {'max_depth': 6, 'n_estimators': 10}\n","0.933 (+/-0.097) for {'max_depth': 6, 'n_estimators': 20}\n","0.952 (+/-0.060) for {'max_depth': 6, 'n_estimators': 30}\n","0.952 (+/-0.085) for {'max_depth': 6, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 6, 'n_estimators': 90}\n","0.933 (+/-0.047) for {'max_depth': 7, 'n_estimators': 10}\n","0.924 (+/-0.076) for {'max_depth': 7, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 40}\n","0.933 (+/-0.047) for {'max_depth': 7, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 7, 'n_estimators': 90}\n","0.943 (+/-0.111) for {'max_depth': 8, 'n_estimators': 10}\n","0.933 (+/-0.047) for {'max_depth': 8, 'n_estimators': 20}\n","0.933 (+/-0.047) for {'max_depth': 8, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 8, 'n_estimators': 90}\n","0.943 (+/-0.111) for {'max_depth': 9, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 9, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 9, 'n_estimators': 90}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 10, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'max_depth': 10, 'n_estimators': 40}\n","0.933 (+/-0.047) for {'max_depth': 10, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 10, 'n_estimators': 90}\n","0.943 (+/-0.111) for {'max_depth': 11, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 11, 'n_estimators': 90}\n","0.933 (+/-0.097) for {'max_depth': 12, 'n_estimators': 10}\n","0.924 (+/-0.076) for {'max_depth': 12, 'n_estimators': 20}\n","0.933 (+/-0.097) for {'max_depth': 12, 'n_estimators': 30}\n","0.933 (+/-0.097) for {'max_depth': 12, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 12, 'n_estimators': 90}\n","0.933 (+/-0.097) for {'max_depth': 13, 'n_estimators': 10}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 20}\n","0.924 (+/-0.076) for {'max_depth': 13, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 40}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 60}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 13, 'n_estimators': 80}\n","0.933 (+/-0.097) for {'max_depth': 13, 'n_estimators': 90}\n","0.933 (+/-0.097) for {'max_depth': 14, 'n_estimators': 10}\n","0.924 (+/-0.129) for {'max_depth': 14, 'n_estimators': 20}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 30}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 40}\n","0.924 (+/-0.076) for {'max_depth': 14, 'n_estimators': 50}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 60}\n","0.933 (+/-0.097) for {'max_depth': 14, 'n_estimators': 70}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 80}\n","0.943 (+/-0.071) for {'max_depth': 14, 'n_estimators': 90}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        13\n","           2       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n"]}],"source":["report = {}\n","for score in scores:\n","  for el in model_lbls:\n","      model = models[el]\n","      #print(model)\n","      clf = GridSearchCV(estimator = model['estimator'],param_grid = model['param'], scoring = score, \n","                          cv = 5, return_train_score = False, n_jobs = 2 ) # this allows using multi-cores\n","      clf.fit(Xtrain, ytrain)\n","      print_results(clf)\n","      report[el] = clf.best_score_"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oz6yUxwdckLT","executionInfo":{"status":"ok","timestamp":1672412335310,"user_tz":-60,"elapsed":318,"user":{"displayName":"Lorenzo Cassano","userId":"15508137722349799832"}},"outputId":"e15a650e-00b1-496d-9652-4499f3dbccae"},"outputs":[{"output_type":"stream","name":"stdout","text":["\t\tFINAL REPORT\n","Decision Tree        \t - score: 0.94%\n","Gaussian Naive Bayes \t - score: 0.93%\n","Linear Perceptron    \t - score: 0.65%\n","Support Vector       \t - score: 0.97%\n","K Nearest Neighbor  \t - score: 0.95%\n","AdaBoost            \t - score: 0.93%\n","Random forest        \t - score: 0.95%\n"]}],"source":["print(\"\\t\\tFINAL REPORT\")\n","for el in report.keys():\n","  print(models[el]['name'], \"\\t - score: {:4.2}%\".format(report[el]))"]}],"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3.7.13 ('res')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"7650257707f3238d5df88771c66da47b78c5077cb779498608c81dcf9deec5b5"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}